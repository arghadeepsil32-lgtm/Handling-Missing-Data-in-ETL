{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Handling Missing Data in ETL\n",
        "\n",
        "**Q1. What are the most common reasons for missing data in ETL pipelines?**\n",
        "\n",
        "Answers ▶\n",
        "\n",
        "1. Source System Issues :\n",
        "Problems often originate before the data even enters the pipeline.\n",
        "\n",
        "- Human Error:\n",
        "\n",
        " - Schema Changes:\n",
        "\n",
        "- Corrupted Source Data:\n",
        "\n",
        "2. Extraction (Ingestion) Failures :\n",
        "Issues occurring while pulling data from the source.\n",
        "\n",
        "- API Rate Limits:\n",
        "\n",
        "- Network Latency/Timeouts:\n",
        "\n",
        "- Incremental Load Logic:\n",
        "\n",
        "3. Transformation & Logic Errors :\n",
        "Data is often lost or filtered out during processing.\n",
        "\n",
        "- Incorrect Joins:\n",
        "\n",
        "- Data Type Mismatches:\n",
        "\n",
        "- Aggressive Filtering:\n",
        "\n",
        "4. Loading & Destination Constraints :\n",
        "The final step where data is written to the data warehouse.\n",
        "\n",
        "- Constraint Violations:\n",
        "\n",
        "- Buffer/Capacity Issues:\n",
        "\n",
        "**Q2. Why is blindly deleting rows with missing values considered a bad practice in ETL?**\n",
        "\n",
        "Answer ▶\n",
        "\n",
        "1. It Introduces Statistical Bias\n",
        "\n",
        "Data is rarely missing purely by chance. In statistics, this is the difference between data being Missing Completely at Random (MCAR) and Missing Not at Random (MNAR).\n",
        "\n",
        "The Situation: Consider a consumer survey in which individuals with higher incomes are less inclined to disclose their pay.\n",
        "\n",
        "The Error: You are disproportionately eliminating high-earning clients from your dataset if you remove every row that has a missing \"Salary\" field.\n",
        "\n",
        "As a result, you will make poor business decisions because your final analysis will be erroneously biased towards lesser wages. The remaining data no longer accurately depicts the population in the real world.\n",
        "\n",
        "2. Considerable Information Loss\n",
        "\n",
        "A single row in an ETL pipeline may have hundreds or even thousands of columns. The deletion of the entire row eliminates legitimate data in all other columns if only one non-critical column (such as \"Middle Name\") is absent.\n",
        "\n",
        "As an illustration, a row may not have a \"Zip Code\" but may have important, legitimate information like \"Purchase History,\" \"Age,\" and \"Product Preference.\"\n",
        "\n",
        "Consequently, deleting the row weakens your downstream models by lowering the sample size available for examining those other variables that are completely legitimate.\n",
        "\n",
        "3. Reduced Statistical PowerEven\n",
        "\n",
        " if the data is missing completely at random, deleting rows reduces your sample size ($N$).\n",
        "\n",
        " 4. Nightmares in Operations and Auditing\n",
        "\n",
        "Row counts are the main statistic used for health checks in a production ETL setup.\n",
        "\n",
        "Data Reconciliation: \"Data loss\" alerts are triggered if your warehouse loads 9,500 rows out of 10,000 that your source system sends because you silently dropped 500 rows with missing values.\n",
        "\n",
        "**Q3. Explain the difference between:**\n",
        "\n",
        "**Listwise deletion**\n",
        "\n",
        "**Column deletion**\n",
        "\n",
        "Answer ▶\n",
        "\n",
        "1. Deletion via List (Row Deletion)\n",
        "\n",
        "This technique, also referred to as \"Complete Case Analysis,\" eliminates a whole record from the dataset if even one value is absent.\n",
        "\n",
        "Reasoning: \"If I don't know everything about this customer, I will ignore them entirely.\"\n",
        "\n",
        "When to apply:\n",
        "\n",
        "- True randomness (MCAR) characterizes the missing data.\n",
        "\n",
        "- Very few rows (less than 5% of the entire dataset) are impacted.\n",
        "\n",
        "- The \"target\" variable—the object you're attempting to predict—has the missing value, and imputation could add excessive noise.\n",
        "\n",
        "Benefits: Easy to apply; maintains the remaining variables' distribution (assuming data is MCAR).\n",
        "\n",
        "Cons: significantly lowers sample size; if data is not missing at random, bias may be introduced.\n",
        "\n",
        "2. Deletion of Columns (Feature Dropping)\n",
        "\n",
        "\n",
        "If a sizable portion of a variable's (column's) values are missing, this technique eliminates the variable from the dataset.\n",
        "\n",
        "Reasoning: \"This specific question (variable) was left blank by so many people that it is useless for analysis.\"\n",
        "\n",
        "\n",
        "When to apply:\n",
        "\n",
        "- More than sixty to seventy percent of the data is missing.\n",
        "\n",
        "- Neither the analysis nor the hypothesis depend on the variable.\n",
        "\n",
        "- Due of its strong correlation with another fully occupied column, the variable is redundant.\n",
        "\n",
        "Advantages: Maintains the maximum number of observations (rows); reduces dimensionality to simplify the model.\n",
        "\n",
        "Cons: For the populated rows, you lose possibly important information that was included in the variable.\n",
        "\n",
        "**Q4. Why is median imputation preferred over mean imputation for skewed data such as income?**\n",
        "\n",
        "Answer ▶\n",
        "\n",
        "1. The Outlier \"Pull\"\n",
        "\n",
        "The total of all values is the arithmetic mean. If your income distribution is \"Right-Skewed\" or \"Positive Skew\":\n",
        "\n",
        "- It is the high incomes who will inflate the Mean.\n",
        "\n",
        "- The bulk of the population is still at the center of the median, or middle value.\n",
        "\n",
        "2. A Specific Illustration\n",
        "\n",
        "Consider the yearly salaries of a small team:\n",
        "\n",
        "- Employees: $45,000, $50,000, $55,000, and $40,000.\n",
        "\n",
        "- CEO: 2 million\n",
        "\n",
        "If the central tendency is computed:\n",
        "\n",
        "Mean Average: $438,000 (no one on the team is accurately represented by this figure).\n",
        "\n",
        "The median, which appropriately depicts a \"typical\" employee, is $50,000.\n",
        "\n",
        "**Q5. What is forward fill and in what type of dataset is it most useful?**\n",
        "\n",
        " Answer ▶\n",
        "\n",
        " Forward fill, also known as \"Last Observation Carried Forward\" in statistics or \"ffill\" in Python's Pandas library, is an imputation technique that moves the most recent valid observation to the subsequent valid one.\n",
        "\n",
        " Forward fill is most useful  for Time Series or Longitudinal datasets where data is ordered sequentially.\n",
        "\n",
        "**Q6. Why should flagging missing values be done before imputation in an ETL workflow?**\n",
        "\n",
        "Answer ▶\n",
        "\n",
        "1. \"Missingness\" is Often a Predictor (Information Signal)\n",
        "\n",
        "The fact that data is missing can be just as important as the data itself.\n",
        "\n",
        "2. Differentiating \"Real\" vs. \"Synthetic\" Data\n",
        "\n",
        "Imputed values are estimates, not facts.\n",
        "\n",
        "3. Monitoring Data Quality & Drift\n",
        "\n",
        "You need to know if your data sources are degrading over time.\n",
        "\n",
        "4. Reversibility and Experimentation\n",
        "\n",
        "Imputation strategies often change.\n",
        "\n",
        "**Q7. Consider a scenario where income is missing for many customers. How can this  missingness itself provide business insights?**\n",
        "\n",
        "Answer ▶\n",
        "\n",
        "1. Risk & Creditworthiness Signal\n",
        "\n",
        "In financial services, customers who refuse to disclose income often represent a distinct risk profile.\n",
        "\n",
        "2. Price Sensitivity & Discount Targeting\n",
        "\n",
        "People who guard their financial data often behave differently in pricing discussions.\n",
        "\n",
        "3. User Experience (UX) Friction Points\n",
        "\n",
        "If a specific demographic consistently drops off at the \"Income\" field in your sign-up form, it reveals a flaw in your onboarding process.\n",
        "\n",
        "4. Segmentation for Marketing Strategy\n",
        "\n",
        "\"Missing Income\" is effectively a customer segment."
      ],
      "metadata": {
        "id": "-mNEBgrWk9hf"
      }
    }
  ]
}